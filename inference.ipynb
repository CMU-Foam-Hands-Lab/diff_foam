{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### **Inference**\n",
    "import os  \n",
    "import sys \n",
    "import argparse  \n",
    "import subprocess \n",
    "import pickle as pkl \n",
    "import collections \n",
    "import math \n",
    "import time \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2 \n",
    "import numpy as np \n",
    "import taichi as ti \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision \n",
    "import rclpy \n",
    "from rclpy.node import Node \n",
    "\n",
    "from threading import Thread\n",
    "from typing import Tuple, Sequence, Dict, Union, Optional, Callable \n",
    "\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler \n",
    "from diffusers.training_utils import EMAModel \n",
    "from diffusers.optimization import get_scheduler \n",
    "\n",
    "from datasets.data_utils import * \n",
    "from model.noise_pred_net import * \n",
    "from model.visual_encoder import * \n",
    "from config import * \n",
    "from foam_env import *\n",
    "\n",
    "# 获取当前时间的时间戳\n",
    "timestamp = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "\n",
    "# Define a function to save ROS bag\n",
    "def save_rosbag(dir_path: str, filename: str = \"\", topics: Optional[List[str]] = None) -> subprocess.Popen:\n",
    "    if topics is None:\n",
    "        topics = [\n",
    "            '/autohand_node/cmd_autohand',\n",
    "            '/diff/xarm/move_joint_cmd',\n",
    "            '/autohand_node/state_autohand',\n",
    "            '/xarm/joint_states',\n",
    "            '/camera/color/image_raw/compressed'\n",
    "        ]\n",
    "    \n",
    "    cmd = [\"ros2\", \"bag\", \"record\", \"-o\", os.path.join(dir_path, filename)] + topics\n",
    "    print(f\"Executing command: {cmd}\")  # Debug: Print the command being executed\n",
    "\n",
    "    try:\n",
    "        return subprocess.Popen(cmd, stdout=subprocess.PIPE)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"ROS bag recording failed with error: {e}\")  # Print error message if an exception occurs\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")  # Print unexpected error messages\n",
    "        raise\n",
    "    \n",
    "# Define the DiffPolicyInfer class\n",
    "class DiffPolicyInfer:\n",
    "    def __init__(self, file_name: str, save_flag: bool, record_flag: bool, ckpt_path: str, save_path: str):\n",
    "        try:\n",
    "            rclpy.init()  \n",
    "            self.num_motors = 23  \n",
    "            self.init_hand_pos = np.array([0.0, 0.0, 0.0285, -0.0295, 0.3258, 0.0, 0.0, 0.0, 0.1020, 0.0, 0.0, -0.0707, 0.0701, 0.0274, 0.0, 0.0143]) \n",
    "            self.init_xarm_pos = np.array([-0.0199, -0.1503, 0.0307, 1.3668, 0.0905, 1.4956, -1.7334])\n",
    "            self.init_pos = np.concatenate([self.init_hand_pos, self.init_xarm_pos])  # Concatenate hand and XArm initial positions\n",
    "            vision_encoder = replace_bn_with_gn(get_resnet('resnet18'))\n",
    "            noise_pred_net = ConditionalUnet1D(\n",
    "                input_dim=action_dim, \n",
    "                global_cond_dim=obs_dim * obs_horizon)\n",
    "            self.nets = nn.ModuleDict({\n",
    "                'vision_encoder': vision_encoder, \n",
    "                'noise_pred_net': noise_pred_net})\n",
    "            print('Visual encoder and noise prediction network Initialized.')  # Print a message indicating that pretrained weights are loaded\n",
    "\n",
    "            self.num_diffusion_iters = 80\n",
    "            self.noise_scheduler = DDPMScheduler(\n",
    "                num_train_timesteps=self.num_diffusion_iters,\n",
    "                beta_schedule='squaredcos_cap_v2',\n",
    "                clip_sample=True,\n",
    "                prediction_type='epsilon'\n",
    "            )\n",
    "            print('Noise scheduler Initialized.')  \n",
    "\n",
    "            self.device = torch.device('cuda')  \n",
    "            self.nets.to(self.device)  \n",
    "\n",
    "            self.ckpt_path = f\"{ckpt_path}/{file_name}.pt\" \n",
    "            print(f\"Full ckpt_path: {self.ckpt_path}\")\n",
    "            if not os.path.isfile(self.ckpt_path): \n",
    "                raise FileNotFoundError(\"Checkpoint file not found!\")\n",
    "\n",
    "            state_dict = torch.load(self.ckpt_path, map_location='cuda')  \n",
    "            self.ema_nets = self.nets\n",
    "            self.ema_nets.load_state_dict(state_dict['model_state_dict'])  \n",
    "            print('Pretrained weights loaded.')   \n",
    "\n",
    "            self.cur_img = None  \n",
    "            self.cur_action = None \n",
    "\n",
    "            self.foam_env = FoamEnv(enable_foam=True, enable_camera=True, reset_foam=True) \n",
    "            foam_env_thread = Thread(target=rclpy.spin, args=(self.foam_env,))\n",
    "            foam_env_thread.start()\n",
    "            time.sleep(1.0)\n",
    "\n",
    "            init_action = self.init_pos  \n",
    "            print(\"init_action:\",init_action)\n",
    "            init_obs = self.foam_env.step(init_action)  \n",
    "            # print(\"init_obs:\", init_obs)\n",
    "            # print(\"init_obs['oimage'] shape:\", init_obs['oimage'].shape)  # (480, 640, 3)\n",
    "            # print(\"init_obs['image'] shape:\", init_obs['image'].shape)  # (240, 320, 3)\n",
    "            # print(\"init_obs['agent_pos'] shape:\", init_obs['agent_pos'].shape)  # (23,)\n",
    "            # print(\"init_obs['agent_pos']:\", init_obs['agent_pos'])  \n",
    "            # cv2.imwrite(\"init_obs_oimage.jpg\", init_obs['oimage'])  # correct\n",
    "            # cv2.imwrite(\"init_obs_image.jpg\", init_obs['image'])  # correct\n",
    "\n",
    "            self.cur_img = init_obs['image']  # (240, 320, 3)\n",
    "            # print(\"init_obs:\",init_obs)\n",
    "            \n",
    "            # print(\"cur_img (if ['oimage']) shape:\", self.cur_img.shape)  # (480, 640, 3)\n",
    "\n",
    "            self.cur_action = init_action  # (23,)\n",
    "            # print(\"cur_action shape:\", self.cur_action.shape) \n",
    "\n",
    "            self.obs_deque = collections.deque([init_obs] * obs_horizon, maxlen=obs_horizon)  \n",
    "            \n",
    "            self.save_flag = save_flag \n",
    "            self.record_flag = record_flag \n",
    "            if self.save_flag or self.record_flag: \n",
    "                self.save_file_name = f\"summer_norm/rosbags/{timestamp}\"\n",
    "                self.save_path = save_path  \n",
    "            self.in_record = False  \n",
    "            if self.record_flag:  \n",
    "                print(\"Starting ROS bag recording...\")  \n",
    "                self.start_saving(self.save_file_name)  \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Initialization failed: {e}\")\n",
    "            rclpy.shutdown()\n",
    "            raise\n",
    "\n",
    "    def finish(self):\n",
    "        try:\n",
    "            if self.save_flag or self.record_flag:   \n",
    "                print(\"Ending ROS bag recording...\")  \n",
    "                self.end_saving()   \n",
    "            self.foam_env.reset()  \n",
    "            time.sleep(1.0)   \n",
    "        except Exception as e:\n",
    "            print(f\"Error during finish: {e}\")  \n",
    "        finally:\n",
    "            rclpy.shutdown()  \n",
    "\n",
    "    def start_saving(self, file_name: str):\n",
    "        if not self.in_record: \n",
    "            print(f\"Starting ROS bag recording at {self.save_path}/{file_name}.bag\")  \n",
    "            self.rosbag_p = save_rosbag(self.save_path, file_name + \".bag\")  \n",
    "            self.in_record = True  \n",
    "\n",
    "    def end_saving(self):\n",
    "        if self.in_record:  \n",
    "            print(\"Terminating ROS bag recording...\")  \n",
    "            self.rosbag_p.terminate()  \n",
    "            self.in_record = False   \n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Perform one-step inference to generate the next action.\n",
    "\n",
    "        Utilize observation data to predict and infer actions.\n",
    "\n",
    "        Process:\n",
    "        1. Collect the most recent observation data.\n",
    "        2. Standardize the observation data.\n",
    "        3. Use the model to predict noise and perform reverse diffusion to generate actions.\n",
    "        4. De-standardize the generated actions and select actions for a future period.\n",
    "\n",
    "        Return:\n",
    "        actions (np.ndarray): The predicted actions.\n",
    "        \"\"\"\n",
    "\n",
    "        B = 1  # batchsize\n",
    "        images = np.stack([x['image'] for x in self.obs_deque])  \n",
    "        images = np.moveaxis(images, -1, 1)   \n",
    "        agent_poses = np.stack([x['agent_pos'] for x in self.obs_deque])   # (2, 23)   \n",
    "        # print(\"agent_poses:\", agent_poses)  \n",
    "\n",
    "        nimages = normalize_images(images)  #  (2, 3, 240, 320)\n",
    "        # nagent_poses = normalize_data(agent_poses, stats=stats)   # (2, 23) \n",
    "\n",
    "        nimages = torch.from_numpy(nimages).to(self.device, dtype=torch.float32) \n",
    "        nagent_poses = torch.from_numpy(agent_poses).to(self.device, dtype=torch.float32)  \n",
    "        # print(\"nimages shape:\", nimages.shape)  # torch.Size([2, 3, 240, 320])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = self.ema_nets['vision_encoder'](nimages)  # torch.Size([2, 512])\n",
    "            obs_features = torch.cat([image_features, nagent_poses], dim=-1)  # torch.Size([2, 535])\n",
    "            obs_cond = obs_features.unsqueeze(0).flatten(start_dim=1)  # torch.Size([1, 1070])  # (B, obs_horizon * obs_dim)\n",
    "\n",
    "            noisy_action = torch.randn((B, pred_horizon, action_dim), device=self.device)\n",
    "            naction = noisy_action  # torch.Size([1, 16, 23])\n",
    "\n",
    "            self.noise_scheduler.set_timesteps(self.num_diffusion_iters)\n",
    "            for k in self.noise_scheduler.timesteps:\n",
    "                noise_pred = self.ema_nets['noise_pred_net'](\n",
    "                    sample=naction,\n",
    "                    timestep=k,\n",
    "                    global_cond=obs_cond\n",
    "                )\n",
    "\n",
    "                naction = self.noise_scheduler.step(\n",
    "                    model_output=noise_pred,\n",
    "                    timestep=k,\n",
    "                    sample=naction\n",
    "                ).prev_sample\n",
    "\n",
    "        naction = naction.detach().to('cpu').numpy()  \n",
    "        naction = naction[0]  \n",
    "        action_pred = unnormalize_data(naction, stats=stats)  \n",
    "        # action_pred = naction\n",
    "\n",
    "        start = obs_horizon - 1\n",
    "        end = start + action_horizon\n",
    "        actions = action_pred[start:end, :]  \n",
    "        print(\"actions:\", actions)\n",
    "        return actions  \n",
    "\n",
    "    def excute(self, action):\n",
    "        \"\"\"\n",
    "        Execute the action and update the observation data.\n",
    "\n",
    "        Parameters:\n",
    "        action (np.ndarray): The action to be executed.\n",
    "        \"\"\"\n",
    "\n",
    "        obs = self.foam_env.step(action)  # Obtain observation data\n",
    "        self.obs_deque.append(obs)  # Save observation data\n",
    "        # print('self.obs_deque:',self.obs_deque)\n",
    "        self.cur_img = obs['image']  # Update current image data\n",
    "        # self.cur_action = action  # Update current action data\n",
    "        self.cur_action = obs['agent_pos']  # Update current action data\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_name = \"tennis_nw\"\n",
    "    save_flag = False\n",
    "    record_flag = False\n",
    "    ckpt_path = \"/home/foamlab/nw/save\"\n",
    "    save_path = \"/home/foamlab/nw/save\"\n",
    "\n",
    "    infer = DiffPolicyInfer(\n",
    "        file_name=file_name,\n",
    "        save_flag=save_flag,\n",
    "        record_flag=record_flag,\n",
    "        ckpt_path=ckpt_path,\n",
    "        save_path=save_path\n",
    "    )\n",
    "    # Main loop\n",
    "\n",
    "action = []\n",
    "simplified_action = []\n",
    "all_xarm_joints = []\n",
    "all_foamhand_joints = []\n",
    "total_action_time = 20\n",
    "time_cnt = 0\n",
    "\n",
    "while time_cnt < total_action_time:\n",
    "    action = infer.step()  \n",
    "    print(\"# ⬆steps \", time_cnt)  \n",
    "\n",
    "    for i in range(len(action)):\n",
    "        infer.excute(action[i])\n",
    "        simplified_action.append(np.round(action[i], 4))\n",
    "\n",
    "        # Extract and save the last 7 dimensions (XArm joints)\n",
    "        xarm_joints = action[i][-7:]\n",
    "        all_xarm_joints.append(xarm_joints)\n",
    "\n",
    "        # Extract and save the first 16 dimensions (FoamHand joints)\n",
    "        foamhand_joints = action[i][:16]\n",
    "        all_foamhand_joints.append(foamhand_joints)\n",
    "    \n",
    "        # Save all XArm joints\n",
    "        np.savetxt(f'{timestamp}_xarm_joints.txt', all_xarm_joints, fmt='%.4f')\n",
    "        \n",
    "        # Save all FoamHand joints\n",
    "        np.savetxt(f'{timestamp}_hand_joints.txt', all_foamhand_joints, fmt='%.4f')\n",
    "    \n",
    "    time_cnt += 1  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
